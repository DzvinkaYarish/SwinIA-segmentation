# @package _global_
experiment: synthetic

dataset:
  n_channels: 3
  noise_type: gaussian
  noise_param: 25
  standardize: True
  mean: [ 119.54093579, 113.56837124, 100.93962098 ]
  std: [ 71.68532506271968, 69.92508170348877, 73.11029057938798 ]

dataset_train:
  _target_: noise2same.dataset.ImagenetSyntheticDataset
  path: ${cwd}/data/Imagenet_val/
  cached: Imagenet_val.npy
  transforms:
    _target_: noise2same.dataset.util.training_augmentations_2d
    crop: 64
  input_size: ${.transforms.crop}  # needed for some models

dataset_valid:
  _target_: noise2same.dataset.Set14SyntheticDataset
  path: ${cwd}/data/Set14/
  transforms:
    _target_: noise2same.dataset.util.validation_transforms_2d
    crop: 64

dataset_test:
  _target_: noise2same.dataset.SyntheticTestDataset
  datasets:
    - _target_: noise2same.dataset.KodakSyntheticDataset
      _partial_: True
      path: ${cwd}/data/Kodak/
      n_repeats: 10
    - _target_: noise2same.dataset.BSD300SyntheticDataset
      _partial_: True
      path: ${cwd}/data/BSD300/test/
      n_repeats: 3
    - _target_: noise2same.dataset.Set14SyntheticDataset
      _partial_: True
      path: ${cwd}/data/Set14/
      n_repeats: 20

training:
  crop: 64
  steps: 50000
  batch_size: 64
  validate: True
