# @package _global_
backbone_name: swinir

backbone:
  _target_: noise2same.backbone.swinir.SwinIR
  in_channels: ${dataset.n_channels}
  embed_dim: 96
  upscale: 1
  window_size: 8
  depths: [ 6, 6, 6, 6, 6, 6 ]
  num_heads: [ 6, 6, 6, 6, 6, 6 ]
  pad_divisor: ${.window_size}  # used in dataset config
  input_size: ${eval:${ceil:${dataset_train.input_size} / ${.pad_divisor}} * ${.pad_divisor}}

head:
  _target_: torch.nn.Identity