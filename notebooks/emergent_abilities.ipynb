{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "628260c5-90bd-4a0a-886e-fe3baee2443e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/gpfs/space/home/dzvenymy/SwinIA-segmentation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5011186a-4a2d-460d-9920-bce4e09d1cc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import einops\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from noise2same.backbone import swinia, unet, unet_b2u\n",
    "from hydra import initialize, compose\n",
    "from hydra.utils import instantiate\n",
    "from omegaconf import OmegaConf\n",
    "from noise2same import util\n",
    "from noise2same.dataset.getter import expand_dataset_cfg\n",
    "from importlib import reload\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Tuple\n",
    "from noise2same.util import crop_as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85cb83f2-0265-46f5-81fd-afbc77772038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "util.register_config_resolvers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fafd691-3a14-4ca4-ba67-d75f9f3019c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "swinia = reload(swinia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cbac382-eaa7-4fb7-be96-822bf6f6ca2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "InstantiationException",
     "evalue": "Error in call to target 'noise2same.dataset.fmd.FMDDataset':\nValueError('Incorrect path, /gpfs/space/home/dzvenymy/SwinIA-segmentation/notebooks/data/FMD not a dir. Current working dir: /gpfs/space/home/dzvenymy/SwinIA-segmentation/notebooks')\nfull_key: dataset_test",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/pt/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:92\u001b[0m, in \u001b[0;36m_call_target\u001b[0;34m(_target_, _partial_, args, kwargs, full_key)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_target_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m<string>:20\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, path, mask_percentage, pad_divisor, channel_last, standardize, standardize_by_channel, n_dim, n_channels, data_range, n_repeats, input_size, mean, std, transforms, mode, part, add_blur_and_noise)\u001b[0m\n",
      "File \u001b[0;32m~/SwinIA-segmentation/noise2same/dataset/abc.py:77\u001b[0m, in \u001b[0;36mAbstractNoiseDataset.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate()\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_image_index()\n",
      "File \u001b[0;32m~/SwinIA-segmentation/noise2same/dataset/abc.py:67\u001b[0m, in \u001b[0;36mAbstractNoiseDataset._validate_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect path, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not a dir. Current working dir: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPath\u001b[38;5;241m.\u001b[39mcwd()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Incorrect path, /gpfs/space/home/dzvenymy/SwinIA-segmentation/notebooks/data/FMD not a dir. Current working dir: /gpfs/space/home/dzvenymy/SwinIA-segmentation/notebooks",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInstantiationException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m denoiser \u001b[38;5;241m=\u001b[39m instantiate(cfg\u001b[38;5;241m.\u001b[39mdenoiser, backbone\u001b[38;5;241m=\u001b[39mbackbone, head\u001b[38;5;241m=\u001b[39mhead)\n\u001b[1;32m     19\u001b[0m expand_dataset_cfg(cfg)\n\u001b[0;32m---> 20\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43minstantiate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#checkpoint = torch.load(path + 'checkpoints/model_last.pth')['model']\u001b[39;00m\n\u001b[1;32m     23\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtp_mice.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/pt/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:226\u001b[0m, in \u001b[0;36minstantiate\u001b[0;34m(config, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m     _convert_ \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mpop(_Keys\u001b[38;5;241m.\u001b[39mCONVERT, ConvertMode\u001b[38;5;241m.\u001b[39mNONE)\n\u001b[1;32m    224\u001b[0m     _partial_ \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mpop(_Keys\u001b[38;5;241m.\u001b[39mPARTIAL, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minstantiate_node\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_recursive_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_convert_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_partial_\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m OmegaConf\u001b[38;5;241m.\u001b[39mis_list(config):\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m# Finalize config (convert targets to strings, merge with kwargs)\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     config_copy \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(config)\n",
      "File \u001b[0;32m~/.conda/envs/pt/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:347\u001b[0m, in \u001b[0;36minstantiate_node\u001b[0;34m(node, convert, recursive, partial, *args)\u001b[0m\n\u001b[1;32m    342\u001b[0m                 value \u001b[38;5;241m=\u001b[39m instantiate_node(\n\u001b[1;32m    343\u001b[0m                     value, convert\u001b[38;5;241m=\u001b[39mconvert, recursive\u001b[38;5;241m=\u001b[39mrecursive\n\u001b[1;32m    344\u001b[0m                 )\n\u001b[1;32m    345\u001b[0m             kwargs[key] \u001b[38;5;241m=\u001b[39m _convert_node(value, convert)\n\u001b[0;32m--> 347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_target_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;66;03m# If ALL or PARTIAL non structured or OBJECT non structured,\u001b[39;00m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;66;03m# instantiate in dict and resolve interpolations eagerly.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert \u001b[38;5;241m==\u001b[39m ConvertMode\u001b[38;5;241m.\u001b[39mALL \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    352\u001b[0m         convert \u001b[38;5;129;01min\u001b[39;00m (ConvertMode\u001b[38;5;241m.\u001b[39mPARTIAL, ConvertMode\u001b[38;5;241m.\u001b[39mOBJECT)\n\u001b[1;32m    353\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m node\u001b[38;5;241m.\u001b[39m_metadata\u001b[38;5;241m.\u001b[39mobject_type \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m    354\u001b[0m     ):\n",
      "File \u001b[0;32m~/.conda/envs/pt/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:97\u001b[0m, in \u001b[0;36m_call_target\u001b[0;34m(_target_, _partial_, args, kwargs, full_key)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_key:\n\u001b[1;32m     96\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mfull_key: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InstantiationException(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mInstantiationException\u001b[0m: Error in call to target 'noise2same.dataset.fmd.FMDDataset':\nValueError('Incorrect path, /gpfs/space/home/dzvenymy/SwinIA-segmentation/notebooks/data/FMD not a dir. Current working dir: /gpfs/space/home/dzvenymy/SwinIA-segmentation/notebooks')\nfull_key: dataset_test"
     ]
    }
   ],
   "source": [
    "# cf_mice\n",
    "# path = '/gpfs/space/home/chizhov/noise2same/noise2same.pytorch/results/fmd/swinia/train/2023-11-15_20-23-08_SSFJW/'\n",
    "# tp_mice\n",
    "# path = '/gpfs/space/home/chizhov/noise2same/noise2same.pytorch/results/fmd/swinia/train/2023-11-16_15-09-54_NZZIB/'\n",
    "# cf_fish\n",
    "# path = '/gpfs/space/home/chizhov/noise2same/noise2same.pytorch/results/fmd/swinia/train/2023-11-16_11-04-57_ZRHCV/'\n",
    "# synthetic\n",
    "# path = '/gpfs/space/home/chizhov/noise2same/noise2same.pytorch/results/synthetic/swinia/train/2023-11-17_13-00-36_QJDGV/'\n",
    "\n",
    "path = '/gpfs/space/projects/transformers_uss/'\n",
    "\n",
    "cfg = OmegaConf.load('/gpfs/space/projects/transformers_uss/config.yaml')\n",
    "cfg.cwd = Path(os.getcwd())\n",
    "OmegaConf.resolve(cfg)\n",
    "backbone = instantiate(cfg.backbone)\n",
    "head = instantiate(cfg.head)\n",
    "denoiser = instantiate(cfg.denoiser, backbone=backbone, head=head)\n",
    "\n",
    "expand_dataset_cfg(cfg)\n",
    "data = instantiate(cfg.dataset_test)\n",
    "\n",
    "#checkpoint = torch.load(path + 'checkpoints/model_last.pth')['model']\n",
    "checkpoint = torch.load(path + 'tp_mice.pth')['model']\n",
    "\n",
    "denoiser.load_state_dict(checkpoint)\n",
    "denoiser.to('cuda');\n",
    "\n",
    "index = 406\n",
    "denoiser.eval()\n",
    "with torch.no_grad():\n",
    "    result = denoiser(data[index]['image'].unsqueeze(0).cuda())\n",
    "\n",
    "vectorized_orig = (data[index]['image'] * data[index]['std'] + data[index]['mean']).numpy()\n",
    "target_shape = data[index]['shape']\n",
    "target_shape[-1] = 144\n",
    "\n",
    "feature_map = result['image'].detach().cpu().numpy()\n",
    "feature_map = crop_as(feature_map[0], target_shape)\n",
    "vectorized_swinia = feature_map.reshape(-1, 144)\n",
    "vectorized_heads = np.split(vectorized_swinia, 16, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7bc7a4-1edc-4420-9dc5-9de46425a91d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "fig, axes = plt.subplots(5, 5)\n",
    "start = 400\n",
    "for index, ax in zip(range(start, start + 25), axes.flat): \n",
    "# image = (data[index]['image'] * data[index]['std'] + data[index]['mean']).numpy()\n",
    "    ax.imshow(data[index]['image'].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdfbce8-07a4-402d-ada6-b449531a1cb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cf_mice\n",
    "# path = '/gpfs/space/home/papkov/swinia/results/fmd/unet/train/2023-03-05_23-46-28/'\n",
    "# tp_mice\n",
    "# path = '/gpfs/space/home/papkov/swinia/results/fmd/unet/train/2023-03-05_23-52-39/'\n",
    "# cf_fish\n",
    "# path = '/gpfs/space/home/papkov/swinia/results/fmd/unet/train/2023-03-05_19-59-25/'\n",
    "# synthetic\n",
    "path = '/gpfs/space/home/papkov/swinia/results/synthetic/unet/train/2023-03-04_19-51-14/'\n",
    "\n",
    "cfg = OmegaConf.load(path + '.hydra/config.yaml')\n",
    "cfg.cwd = Path(os.getcwd())\n",
    "OmegaConf.resolve(cfg)\n",
    "backbone = unet.UNet(in_channels=cfg.data.n_channels, **cfg.backbone)\n",
    "\n",
    "checkpoint = torch.load(path + 'checkpoints/model_last.pth')['model']\n",
    "weights = dict()\n",
    "for key in checkpoint:\n",
    "    if key.startswith('net.'):\n",
    "        weights[key.replace('net.', '')] = checkpoint[key]\n",
    "backbone.load_state_dict(weights)\n",
    "backbone.to('cuda')\n",
    "target_shape[-1] = 96\n",
    "\n",
    "image = (data[index]['image'] * data[index]['std'] + data[index]['mean'])\n",
    "image = (image - image.mean()) / image.std()\n",
    "backbone.eval()\n",
    "with torch.no_grad():\n",
    "    result = backbone(data[index]['image'].unsqueeze(0).cuda())\n",
    "\n",
    "feature_map = result.detach().cpu().numpy()\n",
    "feature_map = crop_as(feature_map.transpose(0, 2, 3, 1)[0], target_shape)\n",
    "vectorized_n2s = feature_map.reshape(-1, 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa24e81-394f-48bf-8b40-bb9bad468776",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cf_mice\n",
    "# path = '/gpfs/space/home/chizhov/Blind2Unblind/pretrained_models/Confocal_MICE_112rf20_beta19.7.pth'\n",
    "# tp_mice\n",
    "# path = '/gpfs/space/home/chizhov/Blind2Unblind/pretrained_models/TwoPhoton_MICE_112rf20_beta20.pth'\n",
    "# cf_fish\n",
    "# path = '/gpfs/space/home/chizhov/Blind2Unblind/pretrained_models/Confocal_FISH_112rf20_beta20.pth'\n",
    "# synthetic\n",
    "path = '/gpfs/space/home/chizhov/Blind2Unblind/pretrained_models/g25_112f20_beta19.7.pth'\n",
    "\n",
    "checkpoint = torch.load(path)\n",
    "del checkpoint['last.2.weight']\n",
    "del checkpoint['last.2.bias']\n",
    "model = unet_b2u.UNetB2UReal(cfg.data.n_channels, cfg.data.n_channels)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.to('cuda')\n",
    "target_shape[-1] = 96\n",
    "\n",
    "image = (data[index]['image'] * data[index]['std'] + data[index]['mean']) / 255\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    result = model(image.unsqueeze(0).cuda())\n",
    "\n",
    "feature_map = result.detach().cpu().numpy()\n",
    "feature_map = crop_as(feature_map.transpose(0, 2, 3, 1)[0], target_shape)\n",
    "vectorized_b2u = feature_map.reshape(-1, 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcefd64-235c-44df-9ed8-12e404d5e277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "# thresh = threshold_otsu(vectorized_orig[0])\n",
    "# binary = vectorized_orig > thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b565ff-555f-408c-81c0-aa2d778145c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(111)\n",
    "k = 2\n",
    "k_means = KMeans(n_clusters=k)\n",
    "k_means.fit(vectorized_swinia)\n",
    "res = k_means.predict(vectorized_swinia)\n",
    "result_swinia = res.reshape(target_shape[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dd052b-2a68-47ab-aac8-c53584b82578",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means = KMeans(n_clusters=k)\n",
    "k_means.fit(vectorized_n2s)\n",
    "res = k_means.predict(vectorized_n2s)\n",
    "result_n2s = res.reshape(target_shape[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32e46e6-d9df-4611-a5c6-1479096f1758",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "k_means = KMeans(n_clusters=k)\n",
    "k_means.fit(vectorized_b2u)\n",
    "res = k_means.predict(vectorized_b2u)\n",
    "result_b2u = res.reshape(target_shape[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0121a0d9-a782-48aa-afc1-2fe634cd2960",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n2s_0 = np.where(result_n2s == 0)\n",
    "n2s_1 = np.where(result_n2s == 1)\n",
    "n2s_2 = np.where(result_n2s == 2)\n",
    "n2s_3 = np.where(result_n2s == 3)\n",
    "\n",
    "b2u_0 = np.where(result_b2u == 0)\n",
    "b2u_1 = np.where(result_b2u == 1)\n",
    "b2u_2 = np.where(result_b2u == 2)\n",
    "b2u_3 = np.where(result_b2u == 3)\n",
    "\n",
    "swin_0 = np.where(result_swinia == 0)\n",
    "swin_1 = np.where(result_swinia == 1)\n",
    "swin_2 = np.where(result_swinia == 2)\n",
    "swin_3 = np.where(result_swinia == 3)\n",
    "\n",
    "result_n2s_ = result_n2s.copy()\n",
    "result_n2s_[n2s_0] = 2\n",
    "result_n2s_[n2s_2] = 0\n",
    "\n",
    "result_b2u_ = result_b2u.copy()\n",
    "result_b2u_[b2u_2] = 0\n",
    "result_b2u_[b2u_1] = 2\n",
    "result_b2u_[b2u_0] = 1\n",
    "\n",
    "result_swinia_ = result_swinia.copy()\n",
    "result_swinia_[swin_2] = 3\n",
    "result_swinia_[swin_1] = 2\n",
    "result_swinia_[swin_3] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea11d4d7-e8dc-49c0-81e7-c0e5b9098747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 10\n",
    "\n",
    "figure_size = 10\n",
    "plt.figure(figsize=(figure_size,figure_size))\n",
    "#original image\n",
    "plt.subplot(1,5,1),plt.imshow(vectorized_orig.transpose(1, 2, 0))\n",
    "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "#image 2\n",
    "# plt.subplot(1,5,2),plt.imshow(binary.transpose(1, 2, 0).astype(int))\n",
    "# plt.title('Original (Otsu)'), plt.xticks([]), plt.yticks([])\n",
    "#image 3\n",
    "plt.subplot(1,5,3),plt.imshow(result_n2s)\n",
    "plt.title('Noise2Same (K = 4)'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(1,5,4),plt.imshow(result_b2u)\n",
    "plt.title('B2U (K = 4)'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(1,5,5),plt.imshow(1-result_swinia)\n",
    "plt.title('SwinIA (K = 4)'), plt.xticks([]), plt.yticks([]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77da5ad8-6dfe-4041-85ff-7f49ec531993",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorized_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6691f3-01c7-4392-9463-4873fb9fbe8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_b2u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422052df-b0c0-45b2-bf85-c45bc56bf817",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inertia = []\n",
    "for k in [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "    k_means = KMeans(n_clusters=k)\n",
    "    k_means.fit(vectorized_swinia)\n",
    "    res = k_means.predict(vectorized_swinia)\n",
    "    result_swinia = res.reshape(target_shape[:2])\n",
    "    inertia.append(k_means.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b21a061-a825-492b-be3c-4097be883341",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot([2, 3, 4, 5, 6, 7], inertia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb39e77b-214d-4171-9f24-51c60a19885b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(vectorized_orig * data[0]['std'] + data[0]['mean']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cbf33a-f636-4c85-ab86-af0d5bbb8279",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def overlay(\n",
    "    image: np.ndarray,\n",
    "    mask: np.ndarray,\n",
    "    color: Tuple[int, int, int] = (255, 0, 0),\n",
    "    alpha: float = 0.5, \n",
    "    resize: Tuple[int, int] = (1024, 1024)\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Combines image and its segmentation mask into a single image.\n",
    "    \n",
    "    Params:\n",
    "        image: Training image.\n",
    "        mask: Segmentation mask.\n",
    "        color: Color for segmentation mask rendering.\n",
    "        alpha: Segmentation mask's transparency.\n",
    "        resize: If provided, both image and its mask are resized before blending them together.\n",
    "    \n",
    "    Returns:\n",
    "        image_combined: The combined image.\n",
    "        \n",
    "    \"\"\"\n",
    "    # if image.ndim == 2:\n",
    "    #     image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB).transpose(2, 0, 1)\n",
    "    # if image.ndim == 3 and image.shape[0] == 1:\n",
    "    #     image = cv2.cvtColor(image[0], cv2.COLOR_GRAY2RGB).transpose(2, 0, 1)\n",
    "    color = np.asarray(color).reshape(1, 1, 3)\n",
    "    colored_mask = np.expand_dims(mask, -1).repeat(3, axis=-1)\n",
    "    masked = np.ma.MaskedArray(image, mask=colored_mask, fill_value=color)\n",
    "    image_overlay = masked.filled()\n",
    "    \n",
    "    if resize is not None:\n",
    "        image = cv2.resize(image.transpose(1, 2, 0), resize)\n",
    "        image_overlay = cv2.resize(image_overlay.transpose(1, 2, 0), resize)\n",
    "    \n",
    "    image_combined = cv2.addWeighted(image, 1 - alpha, image_overlay, alpha, 0)\n",
    "    \n",
    "    return image_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63b30e9-b6f1-4751-a894-1448d6a67cd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorized_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceba819-72a4-41c9-9910-de420020f6ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.family\"] = \"times\"\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "plt.rcParams['axes.titlepad'] = 12\n",
    "\n",
    "alpha = 0.6\n",
    "target_shape[-1] = 3\n",
    "vectorized_orig_ = vectorized_orig.copy()\n",
    "# vectorized_orig = crop_as(vectorized_orig.transpose(1, 2, 0), target_shape)\n",
    "\n",
    "f, ax = plt.subplots(5, 1, figsize=(7, 20))\n",
    "ax[0].imshow(vectorized_orig / 255, cmap='gray');\n",
    "# ax[0].set_title('Original image', rotation='vertical',x=-0.1,y=0.1)\n",
    "# cut_overlay = overlay(vectorized_orig, binary, color=(255, 255, 0), alpha=alpha, resize=None)\n",
    "# ax[1].imshow(cut_overlay.transpose(1, 2, 0) / 255);\n",
    "# ax[1].set_title('Original (Otsu)')\n",
    "cut_overlay = overlay(vectorized_orig, result_n2s, color=(0, 0, 255), alpha=alpha, resize=None)\n",
    "ax[1].imshow(cut_overlay / 255);\n",
    "# ax[2].set_title('Noise2Same (k = 2)')\n",
    "cut_overlay = overlay(vectorized_orig, result_b2u, color=(0, 255, 0), alpha=alpha, resize=None)\n",
    "ax[2].imshow(cut_overlay / 255);\n",
    "# ax[3].set_title('Blind2Unblind (k = 2)')\n",
    "cut_overlay = overlay(vectorized_orig, result_swinia, color=(255, 0, 0), alpha=alpha, resize=None)\n",
    "ax[3].imshow(cut_overlay / 255);\n",
    "# ax[4].set_title('SwinIA (k = 2)')\n",
    "cut_overlay = overlay(vectorized_orig, result_swinia, color=(255, 0, 0), alpha=alpha, resize=None)\n",
    "cut_overlay = overlay(cut_overlay, result_n2s, color=(0, 255, 0), alpha=alpha, resize=None)\n",
    "cut_overlay = overlay(cut_overlay, result_b2u, color=(0, 0, 255), alpha=alpha, resize=None)\n",
    "ax[4].imshow(cut_overlay / 255);\n",
    "# ax[5].set_title('Overlay')\n",
    "for a in ax:\n",
    "    a.axis('off')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('seg_tp_mice.png', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25825f4-58b4-4089-89ee-65d0dcd01dd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clusters = []\n",
    "for head in vectorized_heads:\n",
    "    k_means = KMeans(n_clusters=2, n_init='auto')\n",
    "    k_means.fit(head)\n",
    "    clusters.append(k_means.predict(head))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7b24bf-ff0c-4f02-8c5c-52f1d067cebb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kernel = np.array([\n",
    "    [0, 1, 1, 1, 0],\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [0, 1, 1, 1, 0]\n",
    "], dtype=np.uint8)\n",
    "fig, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
    "for cl, ax in zip(clusters, axes.flat):\n",
    "    # image = cv2.morphologyEx(cl.reshape(512, 512).astype(np.uint8), cv2.MORPH_OPEN, kernel)\n",
    "    image = cl.reshape(512, 512)\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02606eea-9099-4d64-a9f0-8da4f34375ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
